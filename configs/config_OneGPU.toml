#    单机单GPU配置文件
#    该文件包含了训练和评估模型的配置参数。

# 计算设备设置：使用GPU进行训练，若没有GPU可改为"cpu"
device = "cuda"

# 原始数据集路径
data-root = "datasets/data/train"

# 标签文件路径
data-label = "datasets/data/data_labels.csv"

# 数据集划分比例: 验证集和测试集的比例
valid-split-ratio = 0.15
test-split-ratio = 0.15

# 模型名称：指定要使用的模型架构
# 可选值："resnet18", "resnet34", "resnet50"
model-name = "resnet34"

# 批次大小：每次训练迭代使用的样本数量，影响训练速度和内存占用
batch-size = 256  # 根据GPU内存情况可适当调整

# 训练轮次：整个数据集训练的次数
num-epochs = 100

# 数据加载线程数：用于并行加载数据的线程数量，可根据CPU核心数调整
num-workers = 20

# 类别数量：花卉分类任务中的类别总数
num-classes = 0

# 日志打印间隔：每训练多少个批次打印一次日志
log-interval = 10  # 保持不变

# 是否加载检查点：是否从之前保存的模型继续训练
load-checkpoint = true  # 首次训练保持false

# 是否使用预训练模型：是否使用在大规模数据集上预训练的权重初始化模型
load-pretrained = false

# 加载检查点路径：预训练模型或之前保存的检查点路径
load-checkpoint-path = "checkpoints/best-ckpt.pt"

# 最佳模型保存路径：训练过程中性能最好的模型将保存在此路径
#best-checkpoint-path = "checkpoints/best-ckpt.pt"

# 最新模型保存路径：每个epoch结束后，将当前模型保存在此路径
#last-checkpoint-path = "checkpoints/last-ckpt.pt"

# 检查点时间戳目录：用于评估的特定时间戳训练目录
# 例如："20251023_154606"，留空则使用默认路径
checkpoint-timestamp = ""

# 检查点类型：指定要加载的检查点类型，可选值为"best"或"last"
checkpoint-type = "best"

# 自定义检查点路径：直接指定完整的检查点文件路径
# 如果设置了此值，则优先使用此路径，忽略checkpoint-timestamp和checkpoint-type配置
custom-checkpoint-path = ""

# 损失函数类型：指定训练使用的损失函数
# 可选值："cross_entropy", "nll_loss", "bce_with_logits"
loss-function = "cross_entropy"  # 保持不变

# 学习率：控制模型参数更新的步长，较小的值有助于稳定训练
learning-rate = 0.0001

# 权重衰减：L2正则化系数，用于防止过拟合
weight-decay = 0.0005

# 优化器类型：指定训练使用的优化器
# 可选值："adam", "sgd", "rmsprop"
optimizer-type = "adam"

# 学习率调度器类型：指定训练使用的学习率调度器类型
# 可选值："step", "multi_step", "exponential", "cosine", "cosine_warm_restarts"
# 学习率调度器 相关参数去 optim_utils.py 中定义，根据实际情况调整
lr-scheduler-type = "cosine"  # 改为余弦退火调度器，对于大数据集收敛更好

# 学习率调度器步长：每隔多少个epoch调整一次学习率
lr-scheduler-step-size = 10  # 如果使用step调度器，保持不变

# 学习率调度器衰减率：学习率调整的比例
lr-scheduler-gamma = 0.5  # 如果使用step调度器，保持不变

# 早停机制耐心值：连续多少个epoch无性能提升后停止训练
early-stopping-patience = 10  # 略微减少耐心值，防止过度训练