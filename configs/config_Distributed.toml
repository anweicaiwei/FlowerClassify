# 分布式训练配置文件
# 该文件包含了分布式训练和评估模型的配置参数。

# 计算设备设置：使用GPU进行训练
device = "cuda"

# 主节点地址：用于分布式训练通信
master-addr = "localhost"

# 主节点端口：用于分布式训练通信
master-port = "12355"

# 学习率：控制模型参数更新的步长，较小的值有助于稳定训练
# 在分布式训练中，由于总batch size增大，学习率可能需要相应调整
learning-rate = 0.0004

# 批次大小：每次训练迭代使用的样本总量，将被平均分配给各个进程
batch-size = 64

# 训练轮次：整个数据集训练的次数
num-epochs = 50

# 数据加载线程数：每个进程用于并行加载数据的线程数量，可根据CPU核心数调整
num-workers = 8

# 类别数量：花卉分类任务中的类别总数
num-classes = 10

# 权重衰减：L2正则化系数，用于防止过拟合
weight-decay = 0.0001

# 日志打印间隔：每训练多少个批次打印一次日志
log-interval = 10

# 是否加载检查点：是否从之前保存的模型继续训练
load-checkpoint = false

# 是否使用预训练模型：是否使用在大规模数据集上预训练的权重初始化模型
load-pretrained = false

# 加载检查点路径：预训练模型或之前保存的检查点路径
load-checkpoint-path = "checkpoints/best-ckpt_distribute.pt"

## 最佳模型保存路径：训练过程中性能最好的模型将保存在此路径
# best-checkpoint-path = "checkpoints/best-ckpt_distribute.pt"
#
## 最新模型保存路径：每个epoch结束后，将当前模型保存在此路径
# last-checkpoint-path = "checkpoints/last-ckpt_distribute.pt"

# 损失函数类型：指定训练使用的损失函数
loss-function = "cross_entropy"

# 优化器类型：指定训练使用的优化器
optimizer-type = "adam"

# 学习率调度器类型：指定训练使用的学习率调度器类型
lr-scheduler-type = "step"

# 学习率调度器步长：每隔多少个epoch调整一次学习率
lr-scheduler-step-size = 10

# 学习率调度器衰减率：学习率调整的比例
lr-scheduler-gamma = 0.5

# 早停机制耐心值：连续多少个epoch无性能提升后停止训练
early-stopping-patience = 15
